{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77877a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Memory for: Hari\n",
      "Starting Memory Check...\n",
      "\n",
      "Test 1: Based on my profile, what specific job roles should I apply for?\n",
      "Agent: Based on your skills and target goal, here are some specific job roles that you may be suited for:\n",
      "\n",
      "1. **Machine Learning Engineer**: With expertise in Machine Learning, Python, and Signal Processing, you can explore opportunities as a Machine Learning Engineer in industries like tech, finance, or healthcare.\n",
      "2. **AI/ML Research Scientist**: As an AI enthusiast with skills in Machine Learning and Signal Processing, you may be interested in research-oriented roles where you can work on cutting-edge projects and publications.\n",
      "3. **Signal Processing Engineer**: With your expertise in Signal Processing, you can explore opportunities in industries like audio engineering, image processing, or telecommunications.\n",
      "4. **Data Scientist (AI/ML focus)**: As a data scientist with expertise in Machine Learning, Python, and Signal Processing, you can work on projects involving data analysis, visualization, and AI-driven insights.\n",
      "5. **Computer Vision Engineer**: With your skills in Machine Learning and Signal Processing, you may be interested in roles related to computer vision, such as image recognition, object detection, or facial recognition.\n",
      "\n",
      "Some potential companies to explore include:\n",
      "\n",
      "* Tech giants like Google, Microsoft, Amazon\n",
      "* Startups focused on AI/ML research or application\n",
      "* Companies in the healthcare, finance, or automotive industries with a strong emphasis on AI and ML\n",
      "\n",
      "These are just a few examples, but I encourage you to research and explore job roles that align with your interests and skills. Good luck with your job search!\n",
      "\n",
      "Test 2: Which college am I from?\n",
      "Agent: You're from Amrita Vishwa Vidyapeetham. That's a great institution, by the way!\n",
      "\n",
      "Test 3: Do I have any experience with Python?\n",
      "Agent: As per your profile, you have expertise in Python, which means you likely have hands-on experience with it as well.\n"
     ]
    }
   ],
   "source": [
    "# Recall test from JSON file \n",
    "\n",
    "import ollama\n",
    "import json\n",
    "import os\n",
    "\n",
    "MODEL = \"llama3.1:8b\"\n",
    "MEMORY_FILE = r\"update path\"\n",
    "\n",
    "def test_extended_recall():\n",
    "    # Load manual JSON file\n",
    "    if not os.path.exists(MEMORY_FILE):\n",
    "        print(\"Error: Please create test_profile.json first\")\n",
    "        return\n",
    "\n",
    "    with open(MEMORY_FILE, 'r') as f:\n",
    "        memory = json.load(f)\n",
    "    \n",
    "    print(f\"Loaded Memory for: {memory['name']}\")\n",
    "\n",
    "    # Inject Memory into System Prompt\n",
    "    system_prompt = f\"\"\"\n",
    "    You are a Career Advisor.\n",
    "    \n",
    "    USER PROFILE (Long Term Memory):\n",
    "    Name: {memory['name']}\n",
    "    College: {memory['college']}\n",
    "    Skills: {memory['skills']}\n",
    "    Target Goal: {memory['goal']}\n",
    "    \n",
    "    Instructions:\n",
    "    Answer questions based on the User Profile.\n",
    "    \"\"\"\n",
    "\n",
    "    # List of questions to test different memory fields\n",
    "    questions = [\n",
    "        \"Based on my profile, what specific job roles should I apply for?\",\n",
    "        \"Which college am I from?\",\n",
    "        \"Do I have any experience with Python?\"\n",
    "    ]\n",
    "\n",
    "    # Initialize chat history with system prompt\n",
    "    messages = [{'role': 'system', 'content': system_prompt}]\n",
    "\n",
    "    print(\"Starting Memory Check...\")\n",
    "\n",
    "    for i, user_query in enumerate(questions, 1):\n",
    "        print(f\"\\nTest {i}: {user_query}\")\n",
    "        \n",
    "        # Add user question to history\n",
    "        messages.append({'role': 'user', 'content': user_query})\n",
    "        \n",
    "        # Get response\n",
    "        response = ollama.chat(model=MODEL, messages=messages)\n",
    "        answer = response['message']['content']\n",
    "        \n",
    "        print(f\"Agent: {answer}\")\n",
    "        \n",
    "        # Add agent answer to history so it remembers the conversation flow\n",
    "        messages.append({'role': 'assistant', 'content': answer})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_extended_recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dc0190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Simulating Conversation...\n",
      "Chat Input:\n",
      "Hi, I'm Sarah.\n",
      "I am a final year student at IIT Madras.\n",
      "I know Java and Spring Boot, but I want to get into Cloud Computing.\n",
      "I have a certification in AWS.\n",
      "\n",
      "Step 2: Extracting Profile to JSON...\n",
      "Success. Profile saved to: C:\\Users\\hari7\\Documents\\Anokha Hackthon\\file_samples\\generated_profile.json\n",
      "\n",
      "Step 3: Verifying Memory (Asking questions based on the new file)...\n",
      "\n",
      "Q: What is the candidate's name and college?\n",
      "A: The candidate's name is Sarah, and she attends IIT Madras.\n",
      "\n",
      "Q: Does she have any cloud certifications?\n",
      "A: Yes, Sarah has an AWS certification.\n",
      "\n",
      "Q: Based on her interests, what job role would you suggest?\n",
      "A: Given that Sarah's interest lies in Cloud Computing and she already has an AWS certification, I would suggest a role such as a Cloud Engineer or a DevOps Engineer with expertise in designing, deploying, and managing cloud-based systems. Her Java and Spring Boot skills could be valuable assets in this role.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import json\n",
    "import os\n",
    "\n",
    "MODEL = \"llama3.1:8b\"\n",
    "# Update this path to your specific folder\n",
    "SAVE_DIR = r\"update path\"\n",
    "OUTPUT_FILE = os.path.join(SAVE_DIR, \"generated_profile.json\")\n",
    "\n",
    "def test_creation_and_verification():\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(SAVE_DIR):\n",
    "        os.makedirs(SAVE_DIR)\n",
    "\n",
    "    print(\"Step 1: Simulating Conversation...\")\n",
    "    \n",
    "    # 1. Simulate Chat History\n",
    "    chat_history = [\n",
    "        \"Hi, I'm Sarah.\",\n",
    "        \"I am a final year student at IIT Madras.\",\n",
    "        \"I know Java and Spring Boot, but I want to get into Cloud Computing.\",\n",
    "        \"I have a certification in AWS.\"\n",
    "    ]\n",
    "    \n",
    "    full_conversation_text = \"\\n\".join(chat_history)\n",
    "    print(f\"Chat Input:\\n{full_conversation_text}\\n\")\n",
    "    \n",
    "    # 2. Extract Data to JSON\n",
    "    system_prompt_extractor = \"\"\"\n",
    "    You are a Data Extractor.\n",
    "    Read the conversation history and extract the user's details into a JSON object.\n",
    "    Fields required: \"name\", \"college\", \"skills\", \"certifications\", \"interest\".\n",
    "    Output strictly valid JSON only.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Step 2: Extracting Profile to JSON...\")\n",
    "    response = ollama.chat(model=MODEL, messages=[\n",
    "        {'role': 'system', 'content': system_prompt_extractor},\n",
    "        {'role': 'user', 'content': full_conversation_text}\n",
    "    ])\n",
    "    \n",
    "    raw_output = response['message']['content']\n",
    "    \n",
    "    # Parse JSON\n",
    "    try:\n",
    "        if \"```json\" in raw_output:\n",
    "            json_str = raw_output.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"```\" in raw_output:\n",
    "            json_str = raw_output.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "        else:\n",
    "            json_str = raw_output.strip()\n",
    "            \n",
    "        data = json.loads(json_str)\n",
    "        \n",
    "        # Save to file\n",
    "        with open(OUTPUT_FILE, 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "            \n",
    "        print(f\"Success. Profile saved to: {OUTPUT_FILE}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse JSON. Error: {e}\")\n",
    "        return\n",
    "\n",
    "    # 3. Verify Memory (Read the file back and ask questions)\n",
    "    print(\"\\nStep 3: Verifying Memory (Asking questions based on the new file)...\")\n",
    "    \n",
    "    # Load the file we just saved\n",
    "    with open(OUTPUT_FILE, 'r') as f:\n",
    "        memory = json.load(f)\n",
    "\n",
    "    # Create a new agent instance with this memory\n",
    "    system_prompt_agent = f\"\"\"\n",
    "    You are a Career Assistant.\n",
    "    USER PROFILE:\n",
    "    Name: {memory.get('name')}\n",
    "    College: {memory.get('college')}\n",
    "    Skills: {memory.get('skills')}\n",
    "    Certifications: {memory.get('certifications')}\n",
    "    Interest: {memory.get('interest')}\n",
    "    \n",
    "    Answer questions based strictly on this profile.\n",
    "    \"\"\"\n",
    "\n",
    "    verification_questions = [\n",
    "        \"What is the candidate's name and college?\",\n",
    "        \"Does she have any cloud certifications?\",\n",
    "        \"Based on her interests, what job role would you suggest?\"\n",
    "    ]\n",
    "\n",
    "    messages = [{'role': 'system', 'content': system_prompt_agent}]\n",
    "\n",
    "    for q in verification_questions:\n",
    "        print(f\"\\nQ: {q}\")\n",
    "        messages.append({'role': 'user', 'content': q})\n",
    "        \n",
    "        response = ollama.chat(model=MODEL, messages=messages)\n",
    "        answer = response['message']['content']\n",
    "        \n",
    "        print(f\"A: {answer}\")\n",
    "        messages.append({'role': 'assistant', 'content': answer})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_creation_and_verification()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
